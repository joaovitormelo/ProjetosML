{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "Bevk8yg3egcZ",
        "KgNiU1N8eI3H",
        "s6zM8sc1ePGX",
        "_Fq1qoGEev0u",
        "NIiqZBtheZMw",
        "GCa9KzFfhdqH",
        "P5PEbVj8gEt6",
        "md_fE_CYhUyg"
      ],
      "mount_file_id": "1zuAOTNlILEviQ1vzN9MPIvYHgAkNuwLj",
      "authorship_tag": "ABX9TyONnWOJvBe+LXzu2zF1KFCY",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/joaovitormelo/ProjetosML/blob/main/WinesClassifier.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Imports"
      ],
      "metadata": {
        "id": "Bevk8yg3egcZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "import pandas as pd\n",
        "from collections import Counter\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfTransformer\n",
        "from sklearn.svm import SVC"
      ],
      "metadata": {
        "id": "q8TPoaPPejO2"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Carregando os dados"
      ],
      "metadata": {
        "id": "KgNiU1N8eI3H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pathData = 'drive/MyDrive/Colab Notebooks/SupervisedLearning'"
      ],
      "metadata": {
        "id": "VhwNId_0ZdgH"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Carrega o dataset\n",
        "df = pd.read_csv(pathData + '/wines.csv')"
      ],
      "metadata": {
        "id": "G_njMb9hxQo2"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Pré-processando o Dataset"
      ],
      "metadata": {
        "id": "s6zM8sc1ePGX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Filtra apenas colunas relevantes\n",
        "df = df[['description', 'variety']]"
      ],
      "metadata": {
        "id": "9wuQuEnYy_IN"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Cria objeto Counter que recebe uma lista dos valores presentes na coluna \"variety\" (mantendo as repetições/ordem)\n",
        "#São meus labels\n",
        "counter = Counter(df['variety'].tolist())"
      ],
      "metadata": {
        "id": "41L0WyeTzT9B"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Obtém os mais comuns (list of tuples {name, index in list}) e os enumera\n",
        "enumeration = enumerate(counter.most_common(10))\n",
        "#Obtém um dict {name: number[0-9] da enumeração}\n",
        "#Esse número será como eu irei representar cada label, num formato numérico\n",
        "top_10_varieties = {wine[0]: idx for idx, wine in enumeration}\n",
        "print(top_10_varieties)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CFLkwe_70civ",
        "outputId": "27d53fe7-5cd5-4716-8b03-bebc19be5399"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'Pinot Noir': 0, 'Chardonnay': 1, 'Cabernet Sauvignon': 2, 'Red Blend': 3, 'Bordeaux-style Red Blend': 4, 'Riesling': 5, 'Sauvignon Blanc': 6, 'Syrah': 7, 'Rosé': 8, 'Merlot': 9}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "Obtém uma série de booleans correspondentes às rows que serão ou não incluídas\n",
        "dado o valor de \"variety\": deixa só as mais comuns\n",
        "'''\n",
        "filterVariety = df['variety'].map(lambda x: x in top_10_varieties)\n",
        "#Aplica o filtro de rows no df\n",
        "df = df[filterVariety]"
      ],
      "metadata": {
        "id": "OrhZWWkf1-YY"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#obtém a lista dos inputs (nesse caso, as descriptions)\n",
        "description_list = df['description'].tolist()\n",
        "#obtém a lista dos labels: as variedades à qual os \"varietal\" (\n",
        "#vinhos pertencentes a uma certa variedade) pertencem, na forma\n",
        "#numérica\n",
        "varietal_list = [top_10_varieties[var] for var in df['variety'].tolist()]\n",
        "#Converte essa lista para um array do numpy\n",
        "varietal_list = np.array(varietal_list)"
      ],
      "metadata": {
        "id": "3E1w_FBf27Of"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Aplica a técnica Bag of Words sobre a lista de descrições (nossos inputs)\n",
        "#Converte uma coleção de documentos de texto em uma matriz de contagem de tokens\n",
        "#(thus counts)\n",
        "#token = instance of sequence of characters grouped together\n",
        "count_vect = CountVectorizer()\n",
        "x_train_counts = count_vect.fit_transform(description_list)"
      ],
      "metadata": {
        "id": "AR4BIoHfb0zt"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Calcula os TF-IDF dos documentos (relevância de cada token)\n",
        "#Recebe como entrada os counts (bags of words) e retorna os valores processados\n",
        "#com os TF-IDF\n",
        "tfidf_transformer = TfidfTransformer()\n",
        "x_train_tfidf = tfidf_transformer.fit_transform(x_train_counts)"
      ],
      "metadata": {
        "id": "MxjgvYSecDD9"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Utilidades para os Models"
      ],
      "metadata": {
        "id": "_Fq1qoGEev0u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Realiza cross-validation no meu conjunto de inputs (processed in tf-idf format)\n",
        "#e labels (varietal list)\n",
        "train_x, test_x, train_y, test_y = train_test_split(x_train_tfidf, varietal_list, test_size=0.3)"
      ],
      "metadata": {
        "id": "Dc65rsDDd5P8"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Função para calcular precisão do modelo: nº de acertos / nº de samples do teste\n",
        "def getAccuracy():\n",
        "  n_right = 0\n",
        "  for i in range(len(y_score)):\n",
        "    if y_score[i] == test_y[i]:\n",
        "      n_right+=1\n",
        "  return (n_right/float(len(test_y))) * 100"
      ],
      "metadata": {
        "id": "jdCOSGBPe4SW"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Modelo com Naive Bayes"
      ],
      "metadata": {
        "id": "NIiqZBtheZMw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Cria o modelo de Naive Bayes multinomial e o treina com o set de treinamento\n",
        "clf = MultinomialNB().fit(train_x, train_y)\n",
        "#Obtém as predições do modelo no set de testes\n",
        "y_score = clf.predict(test_x)"
      ],
      "metadata": {
        "id": "snQu832hePkk"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Accuracy: %.2f%%\" % getAccuracy())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YXMfWzGddQ5F",
        "outputId": "4dc54b79-dc13-466e-b964-f031c343271b"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 62.55%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Modelo com Deep Learning"
      ],
      "metadata": {
        "id": "V2vxuGTrg7f-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Funções de pré-processamento"
      ],
      "metadata": {
        "id": "GCa9KzFfhdqH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Faz os imports para as funções\n",
        "from nltk import word_tokenize\n",
        "from collections import defaultdict"
      ],
      "metadata": {
        "id": "Nkn6H5uEhBA2"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Break each text document of the corpus into tokens, saving the count of that\n",
        "#token in the dict count. Then, sorts the dict in decrescent order, and return\n",
        "#a list of the top_x words (skipping the first top_n)\n",
        "def count_top_x_words(corpus, top_x, skip_top_n):\n",
        "    count = defaultdict(lambda: 0)\n",
        "    for c in corpus:\n",
        "        for w in word_tokenize(c):\n",
        "            count[w] += 1\n",
        "    count_tuples = sorted([(w, c) for w, c in count.items()], key=lambda x: x[1], reverse=True)\n",
        "    return [i[0] for i in count_tuples[skip_top_n: skip_top_n + top_x]]"
      ],
      "metadata": {
        "id": "7cc9Rl4sWn09"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Turns the corpus into a matrix, in which each row is a text document, and each\n",
        "#column is a number representing a token. Also returns the dict that maps\n",
        "#each token to its number.\n",
        "def replace_top_x_words_with_vectors(corpus, top_x):\n",
        "    topx_dict = {top_x[i]: i for i in range(len(top_x))}\n",
        "\n",
        "    return [\n",
        "        [topx_dict[w] for w in word_tokenize(s) if w in topx_dict]\n",
        "        for s in corpus\n",
        "    ], topx_dict"
      ],
      "metadata": {
        "id": "8ILcWuH1WzWA"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Apply both functions. The general idea is to focus on the common words in the corpus,\n",
        "#and also filter out the most common ones (such as \"a\", \"the\", \"is\", etc)\n",
        "def filter_to_top_x(corpus, n_top, skip_n_top=0):\n",
        "    top_x = count_top_x_words(corpus, n_top, skip_n_top)\n",
        "    return replace_top_x_words_with_vectors(corpus, top_x)"
      ],
      "metadata": {
        "id": "xUmQYSNLZqBp"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Imports das features de Deep Learning"
      ],
      "metadata": {
        "id": "P5PEbVj8gEt6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Conv1D, Flatten\n",
        "from keras.layers import Embedding\n",
        "from keras.preprocessing import sequence\n",
        "from keras.utils import to_categorical\n",
        "import nltk\n",
        "nltk.download('punkt')"
      ],
      "metadata": {
        "id": "yHoEQRMVgbJn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "594d8e79-7d0f-43b6-cf6d-77b44e525469"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Importa e processa dataset novamente"
      ],
      "metadata": {
        "id": "md_fE_CYhUyg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Carrega o dataset\n",
        "df = pd.read_csv(pathData + '/wines.csv')"
      ],
      "metadata": {
        "id": "OQlYqpODhj9w"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Obtém novamente as top 10 variedades\n",
        "counter = Counter(df['variety'].tolist())\n",
        "top_10_varieties = {i[0]: idx for idx, i in enumerate(counter.most_common(10))}\n",
        "#Filtra o dataset para ter apenas a rows que contenham as top 10\n",
        "df = df[df['variety'].map(lambda x: x in top_10_varieties)]"
      ],
      "metadata": {
        "id": "7VQgZ49ehsi5"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Obtém Inputs e Labels"
      ],
      "metadata": {
        "id": "XpaaXEEIiYPq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Pega lista das descriptions (inputs)\n",
        "description_list = df['description'].tolist()\n",
        "#Converte o corpus da input para uma matrix numérica de tokens\n",
        "mapped_list, word_list = filter_to_top_x(description_list, 2500, 10)"
      ],
      "metadata": {
        "id": "8jCHQSTQia2Y"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Pega lista dos labels (varietals) e converte para a codificação numérica\n",
        "varietal_list_o = [top_10_varieties[i] for i in df['variety'].tolist()]\n",
        "#Converte vetor de labels para matriz de binários, em que cada linha é um\n",
        "#varietal (um label) e cada coluna é uma \"classe\" (um dos valores possíveis para o label),\n",
        "#sendo que apenas uma será '1' (a que corresponder à classe do label dessa linha)\n",
        "varietal_list = to_categorical(varietal_list_o)"
      ],
      "metadata": {
        "id": "RGe-3gku_OJy"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Creio que seja uma constante do dataset, o tamanho máximo que uma review pode ter\n",
        "max_review_length = 150\n",
        "#Aplica paddings para preencher com '0's no início de cada linha de mapped_list, a fim de que todas elas tenham o mesmo nº de colunas\n",
        "mapped_list = sequence.pad_sequences(mapped_list, maxlen=max_review_length)"
      ],
      "metadata": {
        "id": "5a27QS4v_M0H"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Cross Validation\n",
        "train_x, test_x, train_y, test_y = train_test_split(mapped_list, varietal_list, test_size=0.3)"
      ],
      "metadata": {
        "id": "UkPFutyh_gIC"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Cria e Treina Modelo"
      ],
      "metadata": {
        "id": "ycLXLp1H_oL4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Determina nº de dimensões do vetor de word embedding\n",
        "embedding_vector_length = 64\n",
        "#Cria o modelo sequencial\n",
        "model = Sequential()"
      ],
      "metadata": {
        "id": "SoHyDPzh_qM_"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#ADIÇÃO DAS CAMADAS\n",
        "#Então é assim. Com o Keras, você cria models sequenciais e pode adicionar\n",
        "#layers à vontade.\n",
        "#Cria layer de word embeddings\n",
        "model.add(Embedding(2500, embedding_vector_length, input_length=max_review_length))\n",
        "#Cria uma convolutional layer, com 50 filtros\n",
        "#e kernel = 5 (tamanho da janela de convolução)\n",
        "model.add(Conv1D(50, 5))\n",
        "#Layer que passa o resultado para 1 única dimensão (creio)\n",
        "model.add(Flatten())\n",
        "#Layer densa com 100 neurônios\n",
        "model.add(Dense(100, activation='relu'))\n",
        "#Camada de output, creio eu, com o número de neurônios igual ao número de classes da saída\n",
        "#A ativação softmax transforma a saída em um distribuição de probabilidades\n",
        "model.add(Dense(max(varietal_list_o) + 1, activation='softmax'))"
      ],
      "metadata": {
        "id": "8YTQFZSj_0KA"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Configura o treinamento do modelo. Define a loss function, e outros parâmetros\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "#Treina o modelo em batchs de tamanho 64 (por atualização de gradiente).\n",
        "#epochs = iterações em todo o conjunto de input e labels\n",
        "model.fit(train_x, train_y, epochs=3, batch_size=64)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OJI9FrqkCjr4",
        "outputId": "26534986-1500-427a-9925-32f44facc08e"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3\n",
            "781/781 [==============================] - 40s 49ms/step - loss: 1.0464 - accuracy: 0.6310\n",
            "Epoch 2/3\n",
            "781/781 [==============================] - 35s 45ms/step - loss: 0.6265 - accuracy: 0.7875\n",
            "Epoch 3/3\n",
            "781/781 [==============================] - 37s 47ms/step - loss: 0.5249 - accuracy: 0.8201\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7c80a9a69d80>"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Testes"
      ],
      "metadata": {
        "id": "8o1O5PBkDouo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Realiza as predições no set de teste\n",
        "y_score = model.predict(test_x)\n",
        "#Como a última layer tem ativação softmax, de distribuição de probabilidades,\n",
        "#converte isso para 0 ou 1, atribuindo à máxima probabilidade o 1, e às outras\n",
        "#o valor 0\n",
        "y_score = [[1 if i == max(sc) else 0 for i in sc] for sc in y_score]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3YyWgXD1r7jY",
        "outputId": "accffff1-8d68-4245-b100-32ae4efe2864"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "669/669 [==============================] - 5s 7ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Contabiliza o nº de acertos para calcular a precisão\n",
        "n_right = 0\n",
        "for i in range(len(y_score)):\n",
        "  if all(y_score[i][j] == test_y[i][j] for j in range(len(y_score[i]))):\n",
        "    n_right += 1\n",
        "\n",
        "print(\"Accuracy: %.2f%%\" % ((n_right/float(len(test_y)) * 100)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zeEGarnEstoY",
        "outputId": "317693b5-d4cc-4603-f512-67bfc1e2dad3"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 76.45%\n"
          ]
        }
      ]
    }
  ]
}